import argparse
import base64
import os
import random
from typing import Literal

import dominate
# pyright: reportWildcardImportFromLibrary=false
from dominate.tags import *
import yaml

from coherence.entities.coreferences import coref_annotation, coref_diagram
from main import get_prediction
from stylometry.logistic_regression import predict_author
from tem.model import TopicEvolution
from tem.process import get_default_te
from train_tem_metrics import predict_from_tem_metrics

def html_results(text: str, author: Literal[0, 1, -1], te: TopicEvolution, entity_diagram: tuple[div, div]) -> str:
    te_img_data = base64.encodebytes(te.graph().pipe(format='png')).decode('ascii')

    doc = dominate.document(title='unBlock analysis')
    with doc:
        container = div(style='max-width: 900px; margin: auto')
        container.add(h1('unBlock analysis'))

        container.add(h2('Full text'))
        for paragraph in text.split('\n'):
            container.add(p(paragraph))

        container.add(h2('Prediction based on Topic Evolution & stilometry markers'))
        container.add(p([
            'We are not sure whether this text was written by a human or generated by a machine.',
            'This text was likely generated by a machine.',
            'This text was likely written by a human.',
        ][author]))

        container.add(h2('Topic Evolution analysis'))
        container.add(img(
            src=f'data:image/png;base64,{te_img_data}',
            style='width: 100%'
        ))

        container.add(h2('Entity occurrence analysis'))
        container.add(entity_diagram[0])
        container.add(h3('Legend'))
        container.add(entity_diagram[1])

    return doc.render()

def analyze_samples(db: list[dict[str, str]], db_name: str, samples: int):
    directory = os.path.join('samples', db_name)
    os.makedirs(directory, exist_ok=True)

    sampled = 0
    while sampled < samples and len(db) > 0:
        print(f'\r\033[Kanalyzing random sample {sampled + 1} of {samples}', end='')

        i = random.choice(range(len(db)))
        text = db.pop(i)['text']
        if not text: continue

        try:
            style_prediction = predict_author(text)
            te = get_default_te(text)
            te_prediction = predict_from_tem_metrics(te)
            author = get_prediction(style_prediction, te_prediction)
            entity_diagram = coref_diagram(coref_annotation(text))
        except: continue

        with open(os.path.join(directory, f'{i}.html'), 'w') as fp:
            fp.write(html_results(text, author, te, entity_diagram))

        sampled += 1

    print('\ndone!')

if __name__ == '__main__':
    parser = argparse.ArgumentParser(prog='Analysis preprocessor')
    parser.add_argument('file', type=str, help='input yaml database file')
    parser.add_argument('--samples', '-n', type=int, required=True, help='number of samples to draw from the database')
    args = parser.parse_args()

    if args.file.endswith('.yaml'):
        print('reading yaml database')
        with open(args.file, 'r') as fp:
            data = yaml.safe_load(fp.read())
            analyze_samples(data, args.file.split('/')[-1].split('.')[0], args.samples)
    else:
        parser.error('Unknown file type')
